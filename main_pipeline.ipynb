{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt\n",
        "#!pip install torch --upgrade\n",
        "!pip install accelerate==0.21.0\n",
        "!pip install optuna tensorboard"
      ],
      "metadata": {
        "id": "YRG2doy1N4JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from modules.dataset import IntelImageClassificationDataset\n",
        "from modules.trainer_2 import Trainer\n",
        "from modules.utility import InferenceSession, Evaluator\n",
        "from modules.profiler import TorchProfiler\n",
        "from optuna_optimizer import OptunaTuner\n",
        "from resolution_tuner import ResolutionTuner\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "\n",
        "# ==== CONFIGURATION ====\n",
        "# Control which scenarios to run individually\n",
        "RUN_BASELINE = False\n",
        "RUN_RESOLUTION_TUNING = False\n",
        "RUN_OPTUNA_HP_TUNING = True\n",
        "\n",
        "# Control detailed profiling for specific runs (e.g., just for diagnostics)\n",
        "# For general comparison runs, keep this False to avoid profiler overhead\n",
        "PERFORM_DETAILED_PROFILING = True # Set this to True only if you need a detailed profiler trace for a specific scenario\n",
        "\n",
        "GLOBAL_SEED = 42\n",
        "\n",
        "torch.manual_seed(GLOBAL_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(GLOBAL_SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ==== MODEL FACTORY ====\n",
        "def build_model():\n",
        "    model = models.squeezenet1_1(weights=models.SqueezeNet1_1_Weights.DEFAULT)\n",
        "    in_channels = model.classifier[1].in_channels\n",
        "    kernel_size = model.classifier[1].kernel_size\n",
        "    model.classifier[1] = nn.Conv2d(in_channels, 6, kernel_size)\n",
        "    return model\n",
        "\n",
        "# Initialize dataset once for baseline and HP tuning (resolution tuning creates its own)\n",
        "initial_resize_val = 150 # Default before resolution tuning\n",
        "dataset_for_baseline = IntelImageClassificationDataset(resize=(initial_resize_val, initial_resize_val))\n",
        "\n",
        "\n",
        "# --- Data Storage for Plotting ---\n",
        "no_opt_history = []\n",
        "resolution_opt_history = []\n",
        "optuna_hp_history = []\n",
        "\n",
        "\n",
        "# ==== SCENARIO 1: NO OPTIMIZATION (BASELINE) ====\n",
        "if RUN_BASELINE:\n",
        "    print(\"\\\\n--- Running Scenario 1: No Optimization (Baseline) ---\")\n",
        "    baseline_model = build_model()\n",
        "    baseline_dataloader = DataLoader(dataset_for_baseline.train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=False)\n",
        "    baseline_optimizer = torch.optim.Adam(baseline_model.parameters(), lr= 0.001)\n",
        "    baseline_epochs = 10\n",
        "\n",
        "    baseline_trainer = Trainer(model=baseline_model, device=DEVICE)\n",
        "    # For baseline, typically no detailed profiler running, just for speed measurement\n",
        "    baseline_profiler = TorchProfiler(use_profiler=True, output_dir=\"./logs/baseline_profiler\", detailed_profiling=PERFORM_DETAILED_PROFILING) # Pass the flag\n",
        "    shutil.rmtree('./logs/baseline_profiler', ignore_errors=True)\n",
        "\n",
        "    with baseline_profiler as prof:\n",
        "        no_opt_history = baseline_trainer.train(baseline_dataloader, epochs=baseline_epochs, optimizer=baseline_optimizer, profiler=prof, silent=False)\n",
        "    print(f\"Baseline Run History (last epoch): {no_opt_history[-1] if no_opt_history else 'N/A'}\")\n",
        "else:\n",
        "    print(\"\\\\n--- Skipping Scenario 1: No Optimization (Baseline) ---\")\n",
        "\n",
        "\n",
        "# ==== SCENARIO 2: RESOLUTION OPTIMIZATION ====\n",
        "best_resolution = initial_resize_val # Fallback if tuning is skipped\n",
        "if RUN_RESOLUTION_TUNING:\n",
        "    print(\"\\\\n--- Running Scenario 2: Resolution Optimization ---\")\n",
        "    res_tuner = ResolutionTuner(model_fn=build_model, device=DEVICE)\n",
        "    print(\"üîç Starting Resolution Tuning...\")\n",
        "    resolution_study = res_tuner.run(n_trials=7) # Adjust n_trials as needed\n",
        "    best_resolution = resolution_study.best_params[\"resolution\"]\n",
        "    print(f\"üìè Best resolution found by Optuna: {best_resolution}\")\n",
        "\n",
        "    # Retrain with the best resolution to capture full training history for plotting\n",
        "    print(f\"--- Retraining with Best Resolution ({best_resolution}) for History ---\")\n",
        "    resolution_dataset = IntelImageClassificationDataset(resize=(best_resolution, best_resolution))\n",
        "    resolution_model = build_model()\n",
        "    # Use a reasonable batch size for retraining, e.g., the baseline one\n",
        "    resolution_dataloader = DataLoader(resolution_dataset.train_dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=False)\n",
        "    resolution_optimizer = torch.optim.Adam(resolution_model.parameters(), lr=0.001) # You might want to tune this LR as well\n",
        "    resolution_epochs = 10 # Default epochs for retraining (match baseline for fair comparison)\n",
        "\n",
        "    resolution_trainer = Trainer(model=resolution_model, device=DEVICE)\n",
        "    resolution_profiler = TorchProfiler(use_profiler=True, output_dir=\"./logs/res_opt_profiler\", detailed_profiling=True) # No detailed profiler during this history capture\n",
        "    shutil.rmtree('./logs/res_opt_profiler', ignore_errors=True)\n",
        "\n",
        "    # Add a scheduler for this retraining run\n",
        "    resolution_scheduler = CosineAnnealingLR(resolution_optimizer, T_max=resolution_epochs)\n",
        "\n",
        "    with resolution_profiler as prof:\n",
        "        resolution_opt_history = resolution_trainer.train(resolution_dataloader, epochs=resolution_epochs, optimizer=resolution_optimizer, profiler=prof, silent=False, scheduler=resolution_scheduler)\n",
        "    print(f\"Resolution Optimized Run History (last epoch): {resolution_opt_history[-1] if resolution_opt_history else 'N/A'}\")\n",
        "else:\n",
        "    print(\"\\\\n--- Skipping Scenario 2: Resolution Optimization ---\")\n",
        "\n",
        "\n",
        "# ==== SCENARIO 3: OPTUNA HYPERPARAMETER OPTIMIZATION ====\n",
        "if RUN_OPTUNA_HP_TUNING:\n",
        "    print(\"\\\\n--- Running Scenario 3: Optuna Hyperparameter Optimization ---\")\n",
        "    # Use the baseline dataset for HP tuning as resolution tuning is a separate step\n",
        "    train_size = int(0.8 * len(dataset_for_baseline.train_dataset))\n",
        "    val_size = len(dataset_for_baseline.train_dataset) - train_size\n",
        "    train_subset, val_subset = random_split(dataset_for_baseline.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(GLOBAL_SEED))\n",
        "\n",
        "    hp_tuner = OptunaTuner(model_fn=build_model, train_dataset=train_subset, val_dataset=val_subset, device=DEVICE)\n",
        "    print(\"üîç Starting Hyperparameter Tuning...\")\n",
        "    hp_study = hp_tuner.run(n_trials=30, seed=GLOBAL_SEED) # Adjust n_trials for more comprehensive search\n",
        "    best_params = hp_study.best_trial.params\n",
        "    print(f\"‚ú® Best Hyperparameters found by Optuna: {best_params}\")\n",
        "\n",
        "    # Retrain with best hyperparameters to capture full training history for plotting\n",
        "    print(\"--- Retraining with Best Hyperparameters for History ---\")\n",
        "    optuna_hp_model = build_model()\n",
        "    # Ensure num_workers=2 and pin_memory=True\n",
        "    optuna_hp_dataloader = DataLoader(train_subset, batch_size=best_params[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n",
        "    optuna_hp_optimizer = torch.optim.Adam(optuna_hp_model.parameters(), lr=best_params[\"lr\"])\n",
        "    optuna_hp_epochs = best_params[\"epochs\"]\n",
        "\n",
        "    optuna_hp_trainer = Trainer(model=optuna_hp_model, device=DEVICE)\n",
        "    optuna_hp_profiler = TorchProfiler(use_profiler=True, output_dir=\"./logs/optuna_hp_profiler\", detailed_profiling=True) # No detailed profiler during this history capture\n",
        "    shutil.rmtree('./logs/optuna_hp_profiler', ignore_errors=True)\n",
        "\n",
        "    # Initialize scheduler for the best Optuna run\n",
        "    optuna_hp_scheduler = CosineAnnealingLR(optuna_hp_optimizer, T_max=optuna_hp_epochs)\n",
        "\n",
        "    with optuna_hp_profiler as prof:\n",
        "        optuna_hp_history = optuna_hp_trainer.train(optuna_hp_dataloader, epochs=optuna_hp_epochs, optimizer=optuna_hp_optimizer, profiler=prof, silent=False, scheduler=optuna_hp_scheduler)\n",
        "    print(f\"Optuna HP Run History (last epoch): {optuna_hp_history[-1] if optuna_hp_history else 'N/A'}\")\n",
        "else:\n",
        "    print(\"\\\\n--- Skipping Scenario 3: Optuna Hyperparameter Optimization ---\")\n",
        "\n",
        "\n",
        "# ==== PLOTTING RESULTS ====\n",
        "print(\"\\\\n--- Plotting Results ---\")\n",
        "\n",
        "histories = {\n",
        "    \"No Optimization\": no_opt_history,\n",
        "    \"Resolution Optimized\": resolution_opt_history,\n",
        "    \"Optuna HP Optimized\": optuna_hp_history\n",
        "}\n",
        "\n",
        "# Remove empty histories if their respective scenarios were skipped\n",
        "histories = {k: v for k, v in histories.items() if v}\n",
        "\n",
        "if not histories:\n",
        "    print(\"No histories collected to plot. Ensure at least one scenario flag (RUN_BASELINE, RUN_RESOLUTION_TUNING, RUN_OPTUNA_HP_TUNING) is True.\")\n",
        "else:\n",
        "    # Convert histories to DataFrames for easier plotting\n",
        "    df_loss = pd.DataFrame()\n",
        "    df_accuracy = pd.DataFrame()\n",
        "\n",
        "    for name, history in histories.items():\n",
        "        if history:\n",
        "            epochs_list = [d['epoch'] for d in history]\n",
        "            loss_list = [d['loss'] for d in history]\n",
        "            accuracy_list = [d['accuracy'] for d in history]\n",
        "\n",
        "            # Use epoch as index for alignment on plots\n",
        "            # Reindex to ensure all dataframes have the same epoch range for clean plotting\n",
        "            max_epoch = max(epochs_list)\n",
        "            full_epochs = range(1, max_epoch + 1)\n",
        "\n",
        "            df_loss[name] = pd.Series(loss_list, index=epochs_list).reindex(full_epochs)\n",
        "            df_accuracy[name] = pd.Series(accuracy_list, index=epochs_list).reindex(full_epochs)\n",
        "\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for col in df_loss.columns:\n",
        "        # Only plot if there's data for this column\n",
        "        if not df_loss[col].isnull().all():\n",
        "            plt.plot(df_loss.index, df_loss[col], label=col, marker='o', markersize=4)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training Loss Comparison\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_loss_comparison.png\")\n",
        "    print(\"Loss plot saved as training_loss_comparison.png\")\n",
        "    plt.show()\n",
        "    # Plot Accuracy\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for col in df_accuracy.columns:\n",
        "        # Only plot if there's data for this column\n",
        "        if not df_accuracy[col].isnull().all():\n",
        "            plt.plot(df_accuracy.index, df_accuracy[col], label=col, marker='o', markersize=4)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training Accuracy Comparison\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"training_accuracy_comparison.png\")\n",
        "    print(\"Accuracy plot saved as training_accuracy_comparison.png\")\n",
        "    plt.show()\n",
        "\n",
        "# ==== SAVE MODEL (example, can be moved/modified) ====\n",
        "model_path = \"./intel_model.pt\"\n",
        "final_model_to_save = None\n",
        "# Prioritize saving the model from Optuna HP if run, else Resolution, else Baseline\n",
        "if RUN_OPTUNA_HP_TUNING and optuna_hp_history:\n",
        "    final_model_to_save = optuna_hp_model\n",
        "elif RUN_RESOLUTION_TUNING and resolution_opt_history:\n",
        "    final_model_to_save = resolution_model\n",
        "elif RUN_BASELINE and no_opt_history:\n",
        "    final_model_to_save = baseline_model\n",
        "else:\n",
        "    print(\"No model trained in a runnable scenario to save.\")\n",
        "\n",
        "\n",
        "if final_model_to_save:\n",
        "    torch.save(final_model_to_save.state_dict(), model_path)\n",
        "    print(f\"‚úÖ Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMojAMhg-svu",
        "outputId": "baae5df3-78e6-4ec6-db29-3e6a89bdbc5a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-09 17:36:19,102] A new study created in memory with name: no-name-2e6c155f-1d87-48fa-ae29-4fd824d24335\n",
            "/content/optuna_optimizer.py:17: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 2e-3)\n",
            "/content/optuna_optimizer.py:20: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
            "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
            "  epochs = trial.suggest_int(\"epochs\", 20, 100, 10)\n",
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-b8a52dc0.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-b8a52dc0.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Skipping Scenario 1: No Optimization (Baseline) ---\n",
            "\\n--- Skipping Scenario 2: Resolution Optimization ---\n",
            "\\n--- Running Scenario 3: Optuna Hyperparameter Optimization ---\n",
            "üîç Starting Hyperparameter Tuning...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.73M/4.73M [00:00<00:00, 78.5MB/s]\n",
            "[I 2025-07-09 17:46:06,653] Trial 0 finished with value: 0.9120057000356252 and parameters: {'lr': 7.274917088027814e-05, 'batch_size': 516, 'epochs': 30}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 18:12:07,683] Trial 1 finished with value: 0.8952618453865336 and parameters: {'lr': 2.2853255256339197e-05, 'batch_size': 1024, 'epochs': 80}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 18:21:49,036] Trial 2 finished with value: 0.8507303170644817 and parameters: {'lr': 1.1152328125494341e-05, 'batch_size': 516, 'epochs': 30}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 18:35:07,857] Trial 3 finished with value: 0.8820805130032062 and parameters: {'lr': 2.642526057549916e-05, 'batch_size': 1024, 'epochs': 40}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 19:00:42,115] Trial 4 finished with value: 0.9045244032775205 and parameters: {'lr': 0.0002557948896094734, 'batch_size': 2300, 'epochs': 60}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 19:10:30,127] Trial 5 finished with value: 0.8745992162451015 and parameters: {'lr': 0.0006407866261851012, 'batch_size': 2300, 'epochs': 20}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 19:58:04,782] Trial 6 finished with value: 0.9098681866761668 and parameters: {'lr': 0.00025002240473339575, 'batch_size': 2300, 'epochs': 100}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 20:18:59,479] Trial 7 finished with value: 0.9041681510509441 and parameters: {'lr': 0.000724680451825845, 'batch_size': 2300, 'epochs': 50}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 20:37:17,689] Trial 8 finished with value: 0.7940862130388315 and parameters: {'lr': 1.909033893292693e-05, 'batch_size': 2300, 'epochs': 40}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 20:50:46,778] Trial 9 finished with value: 0.9070181688635554 and parameters: {'lr': 0.0003345674213696818, 'batch_size': 2300, 'epochs': 30}. Best is trial 0 with value: 0.9120057000356252.\n",
            "[I 2025-07-09 21:17:02,659] Trial 10 finished with value: 0.9137869611685073 and parameters: {'lr': 7.272470336097393e-05, 'batch_size': 516, 'epochs': 70}. Best is trial 10 with value: 0.9137869611685073.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== TESTING PHASE ====\n",
        "print(\"\\n=== TESTING ===\")\n",
        "model_loaded = build_model().to(DEVICE)\n",
        "model_loaded.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
        "model_loaded.eval()\n",
        "\n",
        "session = InferenceSession(model_loaded)\n",
        "# Corrected: Use dataset_for_baseline instead of dataset\n",
        "all_inputs = torch.stack([item[0] for item in dataset_for_baseline.test_dataset])\n",
        "all_targets = torch.tensor([item[1] for item in dataset_for_baseline.test_dataset])\n",
        "output = session(all_inputs)\n",
        "\n",
        "acc = Evaluator.acc(output, all_targets).item()\n",
        "print(f\"üìä Test Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "V0toSJV5RePH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== TESTING PHASE (For Resolution Optimized Scenario ONLY) ====\n",
        "\n",
        "\n",
        "print(\"\\n=== TESTING RESOLUTION OPTIMIZED MODEL ===\")\n",
        "\n",
        "# Check if the resolution model was actually trained and is available\n",
        "if 'resolution_model' in locals() and 'best_resolution' in locals():\n",
        "    try:\n",
        "        # Recreate the model structure\n",
        "        model_loaded = build_model().to(DEVICE)\n",
        "\n",
        "        # Load the state_dict from the 'resolution_model' directly,\n",
        "        # since it's in scope and should be the last model trained when only this scenario runs.\n",
        "        # Alternatively, if it was saved to a specific path like './intel_model_res_opt.pt'\n",
        "        # within your main script's resolution block, you'd load from there.\n",
        "        # For this specific setup (RUN_RESOLUTION_TUNING=True, others False),\n",
        "        # resolution_model will be the final_model_to_save and saved to './intel_model.pt'\n",
        "        # based on your existing saving logic.\n",
        "\n",
        "        # So, we load from './intel_model.pt' which contains the resolution_model's state_dict.\n",
        "        model_path_to_test = \"./intel_model.pt\"\n",
        "        model_loaded.load_state_dict(torch.load(model_path_to_test, map_location=DEVICE))\n",
        "        model_loaded.eval()\n",
        "\n",
        "        session = InferenceSession(model_loaded)\n",
        "\n",
        "        # IMPORTANT: Create the test dataset with the BEST RESOLUTION found for this model\n",
        "        test_dataset_for_resolution_model = IntelImageClassificationDataset(resize=(best_resolution, best_resolution))\n",
        "\n",
        "        all_inputs = torch.stack([item[0] for item in test_dataset_for_resolution_model.test_dataset])\n",
        "        all_targets = torch.tensor([item[1] for item in test_dataset_for_resolution_model.test_dataset])\n",
        "        output = session(all_inputs)\n",
        "\n",
        "        acc = Evaluator.acc(output, all_targets).item()\n",
        "        print(f\"üìä Resolution Optimized Model Test Accuracy (Res: {best_resolution}): {acc:.4f}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ö†Ô∏è Error: Model not found at {model_path_to_test}. Cannot perform testing for resolution optimized model.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è An unexpected error occurred during testing: {e}\")\n",
        "else:\n",
        "    print(\"--- Resolution Optimized Model was not trained or its variables are not accessible for testing. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qy0Z2nQ6vRL",
        "outputId": "d302541d-f833-434b-bb7f-3bd916f550c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TESTING RESOLUTION OPTIMIZED MODEL ===\n",
            "üìä Resolution Optimized Model Test Accuracy (Res: 160): 0.9177\n"
          ]
        }
      ]
    }
  ]
}